{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bdf323b-3ce9-499c-8edd-34b60f67bea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import io\n",
    "import seaborn as sns\n",
    "\n",
    "# Author: Martin Luessi <mluessi@nmr.mgh.harvard.edu>\n",
    "# License: BSD (3-clause)\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "import os.path as op\n",
    "from mne.time_frequency import tfr_multitaper\n",
    "from mne.stats import permutation_cluster_1samp_test as pcluster_test\n",
    "\n",
    "from mne_connectivity import spectral_connectivity_epochs, seed_target_indices\n",
    "from mne.datasets import sample\n",
    "from mne_connectivity.viz import plot_sensors_connectivity\n",
    "from mne.stats import permutation_cluster_test\n",
    "from scipy import stats as stats\n",
    "from functools import partial\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "dict015= {'FP1':'eeg','FP2':'eeg','AF7':'eeg','AF3':'eeg','AFz':'eeg','AF4':'eeg','AF8':'eeg','F7':'eeg','F3':'eeg',\n",
    "          'Fz':'eeg','F4':'eeg','F8':'eeg','FT9':'eeg','FC5':'eeg','FC1':'eeg','FC2':'eeg','FC6':'eeg','FT10':'eeg',\n",
    "          'T7':'eeg','C3':'eeg','Cz':'eeg','C4':'eeg','T8':'eeg','TP9':'eeg','CP5':'eeg','CP1':'eeg', 'CP2':'eeg',\n",
    "          'CP6':'eeg','TP10':'eeg','P7':'eeg','P3':'eeg','Pz':'eeg','P4':'eeg','P8':'eeg', 'O1':'eeg','O2':'eeg',\n",
    "          'DBS1-2':'dbs','DBS2-3':'dbs','DBS3-4':'dbs','DBS4-5':'dbs','DBS5-6':'dbs','DBS6-7':'dbs','DBS7-8':'dbs',\n",
    "          'mean(DBS1-DBS2, DBS2-DBS3, DBS3-DBS4, DBS4-DBS5, DBS5-DBS6, DBS6-DBS7, DBS7-DBS8)':'misc',\n",
    "          'DynL(lc)':'misc','DynR(lc)':'misc','EmgL':'emg','EmgR':'emg','EmgL(lc)':'emg','EmgR(lc)':'emg'}\n",
    "\n",
    "dict013_imp = {'FP1':'eeg','FP2':'eeg','AF7':'eeg','AF3':'eeg','AFz':'eeg','AF4':'eeg','AF8':'eeg','F7':'eeg','F3':'eeg',\n",
    "          'Fz':'eeg','F4':'eeg','F8':'eeg','FC5':'eeg','FC1':'eeg','FC2':'eeg','FC6':'eeg',\n",
    "          'T7':'eeg','C3':'eeg','Cz':'eeg','C4':'eeg','T8':'eeg','FT9':'eeg','CP5':'eeg','CP1':'eeg', 'CP2':'eeg',\n",
    "          'CP6':'eeg','FT10':'eeg','TP9':'eeg','P3':'eeg','Pz':'eeg','P4':'eeg','P8':'eeg', 'O1':'eeg','O2':'eeg',\n",
    "          'DBS1-2':'dbs','DBS2-3':'dbs','DBS3-4':'dbs','DBS4-5':'dbs','DBS5-6':'dbs','DBS6-7':'dbs','DBS7-8':'dbs',\n",
    "          'mean(DBS1-DBS2, DBS2-DBS3, DBS3-DBS4, DBS4-DBS5, DBS5-DBS6, DBS6-DBS7, DBS7-DBS8)':'misc',\n",
    "          'DynL(lc)':'misc','DynR(lc)':'misc','EmgL':'emg','EmgR':'emg','EmgL(lc)':'emg','EmgR(lc)':'emg'}\n",
    "\n",
    "dict013_exp = dict015\n",
    "\n",
    "dict011_imp = {'FP1':'eeg','FP2':'eeg','AF8':'eeg','AF4':'eeg','AFz':'eeg','AF3':'eeg','AF7':'eeg','F8':'eeg','F4':'eeg','Fz':'eeg','F3':'eeg',\n",
    "              'F7':'eeg','FC6':'eeg','FC2':'eeg','FC1':'eeg','FC5':'eeg','T8':'eeg','C4':'eeg','Cz':'eeg','C3':'eeg','T7':'eeg','FT10':'eeg',\n",
    "               'CP6':'eeg','CP2':'eeg','CP1':'eeg', 'CP5':'eeg', 'FT9':'eeg', 'TP10':'eeg','P4':'eeg','Pz':'eeg','P3':'eeg','P7':'eeg','O2':'eeg',\n",
    "               'O1':'eeg', 'DBS1-2':'dbs','DBS2-3':'dbs','DBS3-4':'dbs','DBS4-5':'dbs','DBS5-6':'dbs','DBS6-7':'dbs','DBS7-8':'dbs',\n",
    "              'mean(DBS1-DBS2, DBS2-DBS3, DBS3-DBS4, DBS4-DBS5, DBS5-DBS6, DBS6-DBS7, DBS7-DBS8)':'misc',\n",
    "             'DynR(lc)':'misc', 'DynL(lc)':'misc','EmgR':'emg','EmgL':'emg','EmgR(lc)':'emg','EmgL(lc)':'emg'}\n",
    "\n",
    "dict011_exp = {'FP1':'eeg','FP2':'eeg','AF8':'eeg','AF4':'eeg','AFz':'eeg','AF3':'eeg','AF7':'eeg','F8':'eeg','F4':'eeg','Fz':'eeg','F3':'eeg',\n",
    "              'F7':'eeg','FT10':'eeg', 'FC6':'eeg','FC2':'eeg','FC1':'eeg','FC5':'eeg','FT9':'eeg','T8':'eeg','C4':'eeg','Cz':'eeg','C3':'eeg',\n",
    "               'T7':'eeg','TP10':'eeg','CP6':'eeg','CP2':'eeg','CP1':'eeg', 'CP5':'eeg', 'TP9':'eeg', 'P8':'eeg','P4':'eeg','Pz':'eeg',\n",
    "               'P3':'eeg','P7':'eeg','O2':'eeg', 'O1':'eeg', 'DBS1-2':'dbs','DBS2-3':'dbs','DBS3-4':'dbs','DBS4-5':'dbs','DBS5-6':'dbs',\n",
    "               'DBS6-7':'dbs','DBS7-8':'dbs', 'mean(DBS1-DBS2, DBS2-DBS3, DBS3-DBS4, DBS4-DBS5, DBS5-DBS6, DBS6-DBS7, DBS7-DBS8)':'misc',\n",
    "             'DynR(lc)':'misc', 'DynL(lc)':'misc','EmgR':'emg','EmgL':'emg','EmgR(lc)':'emg','EmgL(lc)':'emg'}\n",
    "           \n",
    "    \n",
    "#'DBS1-234':'dbs','DBS234-567':'dbs','DBS567-8':'dbs','mean(DBS1-234, DBS234-567, DBS567-8)':'dbs',\n",
    "\n",
    "dict08_imp = {'FP1':'eeg','FP2':'eeg','AF8':'eeg','AF4':'eeg','AFz':'eeg','AF3':'eeg','AF7':'eeg','F8':'eeg',\n",
    "                'F4':'eeg','Fz':'eeg','F3':'eeg','F7':'eeg','FT10':'eeg','FC6':'eeg',\n",
    "                'FC2':'eeg','FC1':'eeg','FC5':'eeg','FT9':'eeg','T8':'eeg','C4':'eeg','Cz':'eeg','C3':'eeg',\n",
    "                'T7':'eeg','TP10':'eeg','CP6':'eeg','CP2':'eeg','CP1':'eeg','CP5':'eeg','TP9':'eeg','P4':'eeg',\n",
    "                'Pz':'eeg','P3':'eeg','O2':'eeg','O1':'eeg',\n",
    "                'DBS1-2':'dbs', 'DBS1-3':'dbs', 'DBS1-4':'dbs','DBS2-5':'dbs', 'DBS3-6':'dbs', \n",
    "                'DBS4-7':'dbs', 'DBS5-8':'dbs', 'DBS6-8':'dbs', 'DBS7-8':'dbs',              \n",
    "                'mean(DBS1-2, DBS1-3, DBS1-4, DBS2-5, DBS3-6, DBS4-7, DBS5-8, DBS6-8, DBS7-8)':'misc',             \n",
    "                'DynR(lc)':'misc',\n",
    "                'DynL(lc)':'misc','EmgR':'emg','EmgL':'emg','EmgR(lc)':'emg','EmgL(lc)':'emg'}\n",
    "\n",
    "dict08_exp = {'FP1':'eeg','FP2':'eeg','AF8':'eeg','AF4':'eeg','AFz':'eeg','AF3':'eeg','AF7':'eeg','F8':'eeg',\n",
    "                'F4':'eeg','Fz':'eeg','F3':'eeg','F7':'eeg','FC6':'eeg', 'FC2':'eeg','FC1':'eeg','FC5':'eeg',\n",
    "                'T8':'eeg','C4':'eeg','Cz':'eeg','C3':'eeg', 'T7':'eeg','FT10':'eeg', 'CP6':'eeg','CP2':'eeg',\n",
    "                'CP1':'eeg','CP5':'eeg','FT9':'eeg','TP10':'eeg', 'P4':'eeg','Pz':'eeg','P3':'eeg','P7':'eeg',\n",
    "                'O2':'eeg','O1':'eeg',\n",
    "                'DBS1-2':'dbs', 'DBS1-3':'dbs', 'DBS1-4':'dbs','DBS2-5':'dbs', 'DBS3-6':'dbs', \n",
    "                'DBS4-7':'dbs', 'DBS5-8':'dbs', 'DBS6-8':'dbs', 'DBS7-8':'dbs',              \n",
    "                'mean(DBS1-2, DBS1-3, DBS1-4, DBS2-5, DBS3-6, DBS4-7, DBS5-8, DBS6-8, DBS7-8)':'misc',         \n",
    "                'DynR(lc)':'misc',\n",
    "                'DynL(lc)':'misc','EmgR':'emg','EmgL':'emg','EmgR(lc)':'emg','EmgL(lc)':'emg'}\n",
    "\n",
    "dict07_imp= {'FP1':'eeg','FP2':'eeg','AF8':'eeg','AF4':'eeg','AFz':'eeg','AF3':'eeg','AF7':'eeg','F8':'eeg',\n",
    "                'F4':'eeg','Fz':'eeg','F3':'eeg','F7':'eeg','FT10':'eeg','FC6':'eeg',\n",
    "                'FC2':'eeg','FC1':'eeg','FC5':'eeg','FT9':'eeg','T8':'eeg','C4':'eeg','Cz':'eeg','C3':'eeg',\n",
    "                'T7':'eeg','TP10':'eeg','CP6':'eeg','CP2':'eeg','CP1':'eeg','CP5':'eeg','TP9':'eeg','P4':'eeg',\n",
    "                'Pz':'eeg','P3':'eeg','O2':'eeg','O1':'eeg',\n",
    "                'DBS1-2':'dbs', 'DBS1-3':'dbs', 'DBS1-4':'dbs','DBS2-5':'dbs', 'DBS3-6':'dbs',\n",
    "                'DBS4-7':'dbs', 'DBS5-8':'dbs', 'DBS6-8':'dbs', 'DBS7-8':'dbs',\n",
    "                'mean(DBS1-2, DBS1-3, DBS1-4, DBS2-5, DBS3-6, DBS4-7, DBS5-8, DBS6-8, DBS7-8)':'misc',\n",
    "                'DynR':'misc','DynL':'misc','DynR(lc)':'misc',\n",
    "                'DynL(lc)':'misc','EmgR':'emg','EmgL':'emg','EmgR(lc)':'emg','EmgL(lc)':'emg'}\n",
    "\n",
    "dict07_exp= {'FP1':'eeg','FP2':'eeg','AF8':'eeg','AF4':'eeg','AFz':'eeg','AF3':'eeg','AF7':'eeg','F8':'eeg',\n",
    "                'F4':'eeg','Fz':'eeg','F3':'eeg','F7':'eeg','FT10':'eeg','FC6':'eeg',\n",
    "                'FC2':'eeg','FC1':'eeg','FC5':'eeg','FT9':'eeg','T8':'eeg','C4':'eeg','Cz':'eeg','C3':'eeg',\n",
    "                'T7':'eeg','TP10':'eeg','CP6':'eeg','CP2':'eeg','CP1':'eeg','CP5':'eeg','TP9':'eeg','P8':'eeg','P4':'eeg',\n",
    "                'Pz':'eeg','P3':'eeg','P7':'eeg','O2':'eeg','O1':'eeg',\n",
    "                'DBS1-2':'dbs', 'DBS1-3':'dbs', 'DBS1-4':'dbs','DBS2-5':'dbs', 'DBS3-6':'dbs',\n",
    "                'DBS4-7':'dbs', 'DBS5-8':'dbs', 'DBS6-8':'dbs', 'DBS7-8':'dbs',\n",
    "                'mean(DBS1-2, DBS1-3, DBS1-4, DBS2-5, DBS3-6, DBS4-7, DBS5-8, DBS6-8, DBS7-8)':'misc',\n",
    "                'DynR(lc)':'misc',\n",
    "                'DynL(lc)':'misc','EmgR':'emg','EmgL':'emg','EmgR(lc)':'emg','EmgL(lc)':'emg'}\n",
    "\n",
    "dict_eog= {'FP1':'eog'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c01ca1bb-0344-4ae6-8fb7-5333f55b9132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Average Baseline\"\"\"     \n",
    "def average_baseline(epoch):\n",
    "\n",
    "    epoch_norm1 =[] \n",
    "    for ii,ch in enumerate(epoch.ch_names):\n",
    "        x = np.hstack(epoch.get_data()[:, ii, :]) # 2D dim = epoch* ch* time to 1D dim, freq * (time *epoch)\n",
    "\n",
    "        x_mean=x.mean() # mean of all the freqs across all the complete experiment session.\n",
    "        epoch_norm=[]    \n",
    "        for jj in range(epoch.get_data()[:, ii, :].shape[0]):\n",
    "            epoch_norm.append(((epoch.get_data()[jj, ii, :]-x_mean))) # applying normalaization on each trail\n",
    "        epoch_norm1.append(epoch_norm)\n",
    "    epoch_norm1 = np.array(epoch_norm1)\n",
    "    epoch_norm1 = np.rollaxis(epoch_norm1,1) # normalized epoch data\n",
    "\n",
    "    return mne.EpochsArray(epoch_norm1,  epoch.info, events=epoch.events, tmin=epoch.tmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d56e69c-f794-4792-8a6a-ebeffc46a484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 9 columns\n",
      "600 matching events found\n",
      "No baseline correction applied\n",
      "Setting up band-pass filter from 0.05 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.05\n",
      "- Lower transition bandwidth: 0.05 Hz (-6 dB cutoff frequency: 0.03 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 13201 samples (66.005 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3715812/122343463.py:49: RuntimeWarning: The unit for channel(s) AF3, AF4, AF7, AF8, AFz, C3, C4, CP1, CP2, CP5, CP6, Cz, DBS1-2, DBS2-3, DBS3-4, DBS4-5, DBS5-6, DBS6-7, DBS7-8, EmgL, EmgL(lc), EmgR, EmgR(lc), F3, F4, F7, F8, FC1, FC2, FC5, FC6, FP1, FP2, FT10, FT9, Fz, O1, O2, P3, P4, P7, Pz, T7, T8, TP10 has changed from NA to V.\n",
      "  epochs.set_channel_types(dict1)\n",
      "/tmp/ipykernel_3715812/122343463.py:55: RuntimeWarning: filter_length (13201) is longer than the signal (1801), distortion is likely. Reduce filter length or filter a longer signal.\n",
      "  epochs.filter(0.05,30)\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=1)]: Done 647 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=1)]: Done 881 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=1)]: Done 1151 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=1)]: Done 1457 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=1)]: Done 2177 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=1)]: Done 2591 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=1)]: Done 3041 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=1)]: Done 3527 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=1)]: Done 4049 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=1)]: Done 4607 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=1)]: Done 5201 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=1)]: Done 5831 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=1)]: Done 6497 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=1)]: Done 7199 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=1)]: Done 7937 tasks      | elapsed:    4.5s\n",
      "[Parallel(n_jobs=1)]: Done 8711 tasks      | elapsed:    4.9s\n",
      "[Parallel(n_jobs=1)]: Done 9521 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=1)]: Done 10367 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=1)]: Done 11249 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=1)]: Done 12167 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=1)]: Done 13121 tasks      | elapsed:    7.4s\n",
      "[Parallel(n_jobs=1)]: Done 14111 tasks      | elapsed:    8.0s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 55\u001b[0m\n\u001b[1;32m     52\u001b[0m mon \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mchannels\u001b[38;5;241m.\u001b[39mmake_standard_montage(kind, head_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m epochs\u001b[38;5;241m.\u001b[39mset_montage(mon,match_case\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, on_missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m \u001b[43mepochs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m epochs_aff_odd \u001b[38;5;241m=\u001b[39m epochs[aff_cond[\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m     58\u001b[0m epochs_aff_typ \u001b[38;5;241m=\u001b[39m epochs[aff_cond[\u001b[38;5;241m0\u001b[39m]]\n",
      "File \u001b[0;32m<decorator-gen-79>:12\u001b[0m, in \u001b[0;36mfilter\u001b[0;34m(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mne/filter.py:2575\u001b[0m, in \u001b[0;36mFilterMixin.filter\u001b[0;34m(self, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, phase, fir_window, fir_design, skip_by_annotation, pad, verbose)\u001b[0m\n\u001b[1;32m   2571\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m si, (start, stop) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(onsets, ends)):\n\u001b[1;32m   2572\u001b[0m     \u001b[38;5;66;03m# Only output filter params once (for info level), and only warn\u001b[39;00m\n\u001b[1;32m   2573\u001b[0m     \u001b[38;5;66;03m# once about the length criterion (longest segment is too short)\u001b[39;00m\n\u001b[1;32m   2574\u001b[0m     use_verbose \u001b[38;5;241m=\u001b[39m verbose \u001b[38;5;28;01mif\u001b[39;00m si \u001b[38;5;241m==\u001b[39m max_idx \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2575\u001b[0m     \u001b[43mfilter_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2576\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2577\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2578\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2582\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml_trans_bandwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mh_trans_bandwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2586\u001b[0m \u001b[43m        \u001b[49m\u001b[43miir_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfir_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfir_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfir_design\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfir_design\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_verbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2593\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2594\u001b[0m \u001b[38;5;66;03m# update info if filter is applied to all data channels/vertices,\u001b[39;00m\n\u001b[1;32m   2595\u001b[0m \u001b[38;5;66;03m# and it's not a band-stop filter\u001b[39;00m\n\u001b[1;32m   2596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, _BaseSourceEstimate):\n",
      "File \u001b[0;32m<decorator-gen-74>:12\u001b[0m, in \u001b[0;36mfilter_data\u001b[0;34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mne/filter.py:1041\u001b[0m, in \u001b[0;36mfilter_data\u001b[0;34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001b[0m\n\u001b[1;32m   1026\u001b[0m filt \u001b[38;5;241m=\u001b[39m create_filter(\n\u001b[1;32m   1027\u001b[0m     data,\n\u001b[1;32m   1028\u001b[0m     sfreq,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     fir_design,\n\u001b[1;32m   1039\u001b[0m )\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfir\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1041\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_overlap_add_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1043\u001b[0m     data \u001b[38;5;241m=\u001b[39m _iir_filter(data, filt, picks, n_jobs, copy, phase)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mne/filter.py:368\u001b[0m, in \u001b[0;36m_overlap_add_filter\u001b[0;34m(x, h, n_fft, phase, picks, n_jobs, copy, pad)\u001b[0m\n\u001b[1;32m    364\u001b[0m         x[p] \u001b[38;5;241m=\u001b[39m _1d_overlap_filter(\n\u001b[1;32m    365\u001b[0m             x[p], \u001b[38;5;28mlen\u001b[39m(h), n_edge, phase, cuda_dict, pad, n_fft\n\u001b[1;32m    366\u001b[0m         )\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     data_new \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_edge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpicks\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pp, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(picks):\n\u001b[1;32m    372\u001b[0m         x[p] \u001b[38;5;241m=\u001b[39m data_new[pp]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mne/parallel.py:128\u001b[0m, in \u001b[0;36mparallel_func.<locals>.run_verbose\u001b[0;34m(verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_verbose\u001b[39m(\u001b[38;5;241m*\u001b[39margs, verbose\u001b[38;5;241m=\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlevel, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m use_log_level(verbose\u001b[38;5;241m=\u001b[39mverbose):\n\u001b[0;32m--> 128\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mne/filter.py:397\u001b[0m, in \u001b[0;36m_1d_overlap_filter\u001b[0;34m(x, n_h, n_edge, phase, cuda_dict, pad, n_fft)\u001b[0m\n\u001b[1;32m    394\u001b[0m seg \u001b[38;5;241m=\u001b[39m x_ext[start:stop]\n\u001b[1;32m    395\u001b[0m seg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([seg, np\u001b[38;5;241m.\u001b[39mzeros(n_fft \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(seg))])\n\u001b[0;32m--> 397\u001b[0m prod \u001b[38;5;241m=\u001b[39m \u001b[43m_fft_multiply_repeated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m start_filt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, start \u001b[38;5;241m-\u001b[39m shift)\n\u001b[1;32m    400\u001b[0m stop_filt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start \u001b[38;5;241m-\u001b[39m shift \u001b[38;5;241m+\u001b[39m n_fft, n_x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mne/cuda.py:219\u001b[0m, in \u001b[0;36m_fft_multiply_repeated\u001b[0;34m(x, cuda_dict)\u001b[0m\n\u001b[1;32m    217\u001b[0m x_fft \u001b[38;5;241m=\u001b[39m cuda_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrfft\u001b[39m\u001b[38;5;124m\"\u001b[39m](x, cuda_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_fft\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    218\u001b[0m x_fft \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m cuda_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh_fft\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 219\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mcuda_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mirfft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_fft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/cm/shared/apps/python/gpu/3.10.6/lib/python3.10/site-packages/scipy/fft/_backend.py:25\u001b[0m, in \u001b[0;36m_ScipyBackend.__ua_function__\u001b[0;34m(method, args, kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/cm/shared/apps/python/gpu/3.10.6/lib/python3.10/site-packages/scipy/fft/_pocketfft/basic.py:97\u001b[0m, in \u001b[0;36mc2r\u001b[0;34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     94\u001b[0m     tmp, _ \u001b[38;5;241m=\u001b[39m _fix_shape_1d(tmp, (n\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, axis)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Note: overwrite_x is not utilized\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc2r\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_dir = \"/mnt/beegfs/malann/codes/Oddball_Project/Oddball Data/\"\n",
    "result_dir = \"/mnt/beegfs/malann/codes/Oddball_Project/Results/\"\n",
    "subj_list = ['007']\n",
    "#subj_list = ['015']\n",
    "\n",
    "stage = ['implant']#, 'implant']explant\n",
    "aff_cond = ['1', '101'];\n",
    "aff_cond_plot = ['Standard', 'Oddball'];\n",
    "hand = 'aff'\n",
    "\n",
    "naff_cond = ['10', '110'];\n",
    "\n",
    "for sub in subj_list:\n",
    "    for st in stage:\n",
    "        data_dir = base_dir+\"EDEN\"+sub+'/ANALYSIS/'\n",
    "        fname = data_dir+\"data_clean\"+st+'.mat'\n",
    "        \n",
    "        if hand == 'naff':\n",
    "            fname = data_dir+\"data_clean\"+st+'_naff_cond.mat'\n",
    "            dyno = 'DynR(lc)'\n",
    "        else:\n",
    "            fname = data_dir+\"data_clean\"+st+'.mat'\n",
    "            dyno = 'DynL(lc)'          \n",
    "\n",
    "        \n",
    "        if sub == '015' or sub=='014':\n",
    "            dict1 = dict015\n",
    "        elif sub == '013' and st== 'implant':\n",
    "            dict1 = dict013_imp\n",
    "        elif sub == '013' and st== 'explant':\n",
    "            dict1 = dict013_exp\n",
    "        elif sub == '011' and st== 'implant':\n",
    "            dict1 = dict011_imp\n",
    "        elif sub == '011' and st== 'explant':\n",
    "            dict1 = dict011_exp\n",
    "        elif sub == '008' and st== 'implant':\n",
    "            dict1 = dict08_imp\n",
    "        elif sub == '008' and st== 'explant':\n",
    "            dict1 = dict08_exp\n",
    "        elif sub == '007' and st== 'implant':\n",
    "            dict1 = dict07_imp\n",
    "        elif sub == '007' and st== 'explant':\n",
    "            dict1 = dict07_exp\n",
    "\n",
    "        info = mne.create_info(list(dict1.keys()), sfreq=200, ch_types='misc', verbose=None)\n",
    "        epochs = mne.read_epochs_fieldtrip(fname,info,data_name='x', trialinfo_column=0)\n",
    "        \n",
    "        sfreq = epochs.info['sfreq']\n",
    "        \n",
    "        epochs.set_channel_types(dict1)\n",
    "\n",
    "        kind='easycap-M1'\n",
    "        mon = mne.channels.make_standard_montage(kind, head_size='auto')\n",
    "        epochs.set_montage(mon,match_case=False, on_missing='ignore')\n",
    "        \n",
    "        epochs.filter(0.05,30)\n",
    "\n",
    "        epochs_aff_odd = epochs[aff_cond[1]]\n",
    "        epochs_aff_typ = epochs[aff_cond[0]]\n",
    "\n",
    "\n",
    "        \n",
    "        epochs_aff_typ_E = epochs_aff_typ.copy()\n",
    "        epochs_aff_typ_NE = epochs_aff_typ.copy()\n",
    "        \n",
    "        # calculate outlier trial\n",
    "        tmax = 6\n",
    "        Dynmo_odd = epochs_aff_odd.copy().crop(-1,tmax).get_data(picks=dyno)\n",
    "        Dynmo_odd = Dynmo_odd.reshape(Dynmo_odd.shape[0],Dynmo_odd.shape[2])\n",
    "        \n",
    "        t_target = int(200+200*1.5)\n",
    "        #Calculate Error Rate\n",
    "        ERR_value = []\n",
    "        for i in range(len(Dynmo_odd)):\n",
    "            ERR_value1 = ((Dynmo_odd[i,:].max()-Dynmo_odd[i,t_target])*100)/Dynmo_odd[i,t_target]\n",
    "            ERR_value.append(ERR_value1)\n",
    "        \n",
    "        over_thres = 20\n",
    "        \n",
    "        outlier_idx=[]\n",
    "        outlier_idx_odd_no_err=[]\n",
    "        for j,m in enumerate(ERR_value):\n",
    "            if (m>over_thres):\n",
    "                outlier_idx.append(j)\n",
    "            else:\n",
    "                outlier_idx_odd_no_err.append(j)\n",
    "        \n",
    "        epochs_aff_odd_E=epochs_aff_odd[outlier_idx]\n",
    "        epochs_aff_odd_NE=epochs_aff_odd[outlier_idx_odd_no_err]\n",
    "        \n",
    "        mne.epochs.equalize_epoch_counts([epochs_aff_odd_E,epochs_aff_typ_E], method='truncate')\n",
    "        mne.epochs.equalize_epoch_counts([epochs_aff_odd_NE,epochs_aff_typ_NE], method='truncate')\n",
    "\n",
    "        epochs_aff_odd_E.set_channel_types(dict_eog)\n",
    "        epochs_aff_odd_NE.set_channel_types(dict_eog)\n",
    "        epochs_aff_typ_E.set_channel_types(dict_eog)\n",
    "        epochs_aff_typ_NE.set_channel_types(dict_eog)   \n",
    "\n",
    "\n",
    "        base_min,base_max = -0.9,-0.4\n",
    "        avg = False\n",
    "        \n",
    "        if avg == True:\n",
    "            \n",
    "            epochs_aff_odd_E = average_baseline(epochs_aff_odd_E)\n",
    "            epochs_aff_odd_NE = average_baseline(epochs_aff_odd_NE)\n",
    "            epochs_aff_typ_E = average_baseline(epochs_aff_typ_E)\n",
    "            epochs_aff_typ_NE = average_baseline(epochs_aff_typ_NE)\n",
    "        else:\n",
    "            \n",
    "            epochs_aff_odd_E = epochs_aff_odd_E.apply_baseline((base_min,base_max))\n",
    "            epochs_aff_odd_NE = epochs_aff_odd_NE.apply_baseline((base_min,base_max))\n",
    "            epochs_aff_typ_E = epochs_aff_typ_E.apply_baseline((base_min,base_max))\n",
    "            epochs_aff_typ_NE = epochs_aff_typ_NE.apply_baseline((base_min,base_max))\n",
    "    \n",
    "\n",
    "\n",
    "        f_max_time = np.argmax(epochs_aff_odd_E.copy().crop(0,1).get_data(picks='DynL(lc)').reshape(epochs_aff_odd_E.copy().crop(0,1).get_data(picks='DynL(lc)').shape[0],epochs_aff_odd_E.copy().crop(0,1).get_data(picks='DynL(lc)').shape[2]).mean(axis=0))/200\n",
    "\n",
    "        \n",
    "        # Pick Ipsilesional and DBS channels only\n",
    "        seed_chs = epochs_aff_odd_E.copy().pick('dbs').ch_names\n",
    "        \n",
    "        ch_picks =['Fz','F4','F8','FC2','FC6','Cz', 'C4','CP2','CP6','Pz','P4']\n",
    "        #ch_picks = ['FC2', 'FC1', 'Cz', 'Fz', 'CP2', 'CP1', 'Pz']\n",
    "\n",
    "\n",
    "        \n",
    "        ch_picks.extend(seed_chs)\n",
    "        epochs_aff_odd_E.pick(ch_picks)\n",
    "        epochs_aff_typ_E.pick(ch_picks)\n",
    "        epochs_aff_odd_NE.pick(ch_picks)\n",
    "        epochs_aff_typ_NE.pick(ch_picks)\n",
    "        \n",
    "        rng = np.random.default_rng(42)  # set a random seed\n",
    "        \n",
    "        tmin_coh_lst = [0] #0 , f_max_time # Error detection, Error correction, Full time\n",
    "        tmax_coh_lst = [1.5] #1.5 f_max_time, \n",
    "            \n",
    "        for tmin_coh, tmax_coh in zip(tmin_coh_lst, tmax_coh_lst):\n",
    "            coh_diff_E_permuted = []\n",
    "            coh_diff_NE_permuted = []\n",
    "            \n",
    "            n_perms = 2000\n",
    "            \n",
    "            for iperm in range(n_perms):\n",
    "            # Define different time windows to look for coherence in Error detection and Error correction\n",
    "            \n",
    "\n",
    "                picks = mne.pick_types(epochs_aff_odd_E.info, eeg=True, dbs=True, emg= False,stim=False, eog=False,\n",
    "                                       exclude='bads')\n",
    "            \n",
    "                epochs_aff_odd_E.pick(['eeg','dbs'])\n",
    "                epochs_aff_typ_E.pick(['eeg','dbs'])\n",
    "                epochs_aff_odd_NE.pick(['eeg','dbs'])\n",
    "                epochs_aff_typ_NE.pick(['eeg','dbs'])\n",
    "                \n",
    "                # Use 'DBS' channels as seed\n",
    "                        \n",
    "                seed_chs = epochs_aff_odd_E.copy().pick('dbs').ch_names\n",
    "                coh_E_diff = []\n",
    "                coh_NE_diff = []\n",
    "                for n_seed, seed_ch in enumerate(seed_chs):\n",
    "                    \n",
    "                    picks_ch_names = epochs_aff_odd_E.ch_names\n",
    "                    # Create seed-target indices for connectivity computation\n",
    "                    seed = len(epochs_aff_odd_E.ch_names)-1\n",
    "                    targets = np.arange(len(picks))\n",
    "                    indices = seed_target_indices(seed, targets) \n",
    "\n",
    "\n",
    "\n",
    "                    # permuting for oddball only seed dbs channel   \n",
    "                    ep_dbs_seed = epochs_aff_odd_E.copy().pick([seed_ch])\n",
    "                    perm = rng.permutation(len(ep_dbs_seed))\n",
    "                    epochs_in_permuted_order = ep_dbs_seed[perm]\n",
    "                    random_dbs = epochs_in_permuted_order.get_data()\n",
    "                    epochs_aff_odd_E_drop_seed = epochs_aff_odd_E.copy().drop_channels([seed_ch]).get_data()                \n",
    "                    new_epochs_aff_odd_E = np.concatenate((epochs_aff_odd_E_drop_seed, random_dbs), axis=1)\n",
    "                    new_epochs_aff_odd_E = mne.EpochsArray(new_epochs_aff_odd_E, epochs_aff_odd_E.info, events=epochs_aff_odd_E.events, \n",
    "                                                           tmin=epochs_aff_odd_E.tmin)\n",
    "\n",
    "            \n",
    "                    # permuting for standard only seed dbs channel            \n",
    "                    ep_typ_E_dbs_seed = epochs_aff_typ_E.copy().pick([seed_ch])            \n",
    "                    epochs_typ_E_in_permuted_order = ep_typ_E_dbs_seed[perm]\n",
    "                    random_typ_E_dbs = epochs_typ_E_in_permuted_order.get_data()                    \n",
    "                    epochs_aff_typ_E_drop_seed = epochs_aff_typ_E.copy().drop_channels([seed_ch]).get_data()                \n",
    "                    new_epochs_aff_typ_E = np.concatenate((epochs_aff_typ_E_drop_seed, random_typ_E_dbs), axis=1)\n",
    "                    new_epochs_aff_typ_E = mne.EpochsArray(new_epochs_aff_typ_E, epochs_aff_typ_E.info, events=epochs_aff_typ_E.events, \n",
    "                                                          tmin=epochs_aff_typ_E.tmin)\n",
    "            \n",
    "                    \n",
    "                    \n",
    "                    # permuting for oddball only seed dbs channel   \n",
    "                    ep_dbs_seed_NE = epochs_aff_odd_NE.copy().pick([seed_ch])\n",
    "                    perm = rng.permutation(len(ep_dbs_seed_NE))\n",
    "                    epochs_in_permuted_order_NE = ep_dbs_seed_NE[perm]\n",
    "                    random_dbs_NE = epochs_in_permuted_order_NE.get_data()\n",
    "                    epochs_aff_odd_NE_drop_seed = epochs_aff_odd_NE.copy().drop_channels([seed_ch]).get_data()                \n",
    "                    new_epochs_aff_odd_NE = np.concatenate((epochs_aff_odd_NE_drop_seed, random_dbs_NE), axis=1)\n",
    "                    new_epochs_aff_odd_NE = mne.EpochsArray(new_epochs_aff_odd_NE, epochs_aff_odd_NE.info, events=epochs_aff_odd_NE.events, \n",
    "                                                           tmin=epochs_aff_odd_NE.tmin)\n",
    "\n",
    "\n",
    "                \n",
    "                    # permuting for standard only seed dbs channel            \n",
    "                    ep_typ_NE_dbs_seed = epochs_aff_typ_NE.copy().pick([seed_ch])            \n",
    "                    epochs_typ_NE_in_permuted_order = ep_typ_NE_dbs_seed[perm]\n",
    "                    random_typ_NE_dbs = epochs_typ_NE_in_permuted_order.get_data()                    \n",
    "                    epochs_aff_typ_NE_drop_seed = epochs_aff_typ_NE.copy().drop_channels([seed_ch]).get_data()                \n",
    "                    new_epochs_aff_typ_NE = np.concatenate((epochs_aff_typ_NE_drop_seed, random_typ_NE_dbs), axis=1)\n",
    "                    new_epochs_aff_typ_NE = mne.EpochsArray(new_epochs_aff_typ_NE, epochs_aff_typ_NE.info, events=epochs_aff_typ_NE.events, \n",
    "                                                          tmin=epochs_aff_typ_NE.tmin)\n",
    "\n",
    "                    \n",
    "                \n",
    "                    freq_band = ['Theta', 'Alpha', 'Low beta', 'High beta']\n",
    "                    min_freq = (4, 8,13,21)\n",
    "                    max_freq = (7, 12,20,30)    \n",
    "                    \n",
    "                    # Define wavelet frequencies and number of cycles\n",
    "                    cwt_freqs = np.arange(1, 41, 1)\n",
    "                    cwt_n_cycles = 7\n",
    "                \n",
    "                    # Run the connectivity analysis using 2 parallel jobs\n",
    "                    con_odd_E = spectral_connectivity_epochs(\n",
    "                        new_epochs_aff_odd_E, indices=indices,\n",
    "                        method='coh', mode='cwt_morlet', sfreq=sfreq, fmin = min_freq, fmax = max_freq, faverage =True, tmin = tmin_coh, tmax =tmax_coh,\n",
    "                        cwt_freqs=cwt_freqs, cwt_n_cycles=cwt_n_cycles, n_jobs=30)\n",
    "                \n",
    "                    con_typ_E = spectral_connectivity_epochs(\n",
    "                        new_epochs_aff_typ_E, indices=indices,\n",
    "                        method='coh', mode='cwt_morlet', sfreq=sfreq, fmin = min_freq, fmax = max_freq, faverage =True, tmin = tmin_coh, tmax =tmax_coh,\n",
    "                        cwt_freqs=cwt_freqs, cwt_n_cycles=cwt_n_cycles, n_jobs=30)\n",
    "            \n",
    "                    con_odd_NE = spectral_connectivity_epochs(\n",
    "                        new_epochs_aff_odd_NE, indices=indices,\n",
    "                        method='coh', mode='cwt_morlet', sfreq=sfreq, fmin = min_freq, fmax = max_freq, faverage =True, tmin = tmin_coh, tmax =tmax_coh,\n",
    "                        cwt_freqs=cwt_freqs, cwt_n_cycles=cwt_n_cycles, n_jobs=30)\n",
    "                \n",
    "                    con_typ_NE = spectral_connectivity_epochs(\n",
    "                        new_epochs_aff_typ_NE, indices=indices,\n",
    "                        method='coh', mode='cwt_morlet', sfreq=sfreq, fmin = min_freq, fmax = max_freq, faverage =True, tmin = tmin_coh, tmax =tmax_coh,\n",
    "                        cwt_freqs=cwt_freqs, cwt_n_cycles=cwt_n_cycles, n_jobs=30)\n",
    "            \n",
    "                    \n",
    "                    times = con_odd_E.times\n",
    "                    freqs = con_odd_E.freqs\n",
    "                \n",
    "                    # Mark the seed channel with a value of 1.0, so we can see it in the plot\n",
    "                    # con_odd.get_data()[np.where(indices[1] == seed)] = 1.0\n",
    "                    # con_typ.get_data()[np.where(indices[1] == seed)] = 1.0\n",
    "                \n",
    "                    #layout = mne.find_layout(epochs.info, 'eeg')  # use full layout\n",
    "                    tfr_odd_E = mne.time_frequency.AverageTFR(epochs_aff_odd_E.info, con_odd_E.get_data(), times, freqs, len(epochs_aff_odd_E))\n",
    "                    tfr_odd_E.save(data_dir+'tfr_odd_E'+st+seed_ch+'-tfr.h5',overwrite =True)\n",
    "                \n",
    "                    tfr_typ_E = mne.time_frequency.AverageTFR(epochs_aff_typ_E.info, con_typ_E.get_data(), times, freqs, len(epochs_aff_typ_E))\n",
    "                    tfr_typ_E.save(data_dir+'tfr_typ_E'+st+seed_ch+'-tfr.h5',overwrite =True)\n",
    "            \n",
    "                    #layout = mne.find_layout(epochs.info, 'eeg')  # use full layout\n",
    "                    tfr_odd_NE = mne.time_frequency.AverageTFR(epochs_aff_odd_NE.info, con_odd_NE.get_data(), times, freqs, len(epochs_aff_odd_NE))\n",
    "                    tfr_odd_NE.save(data_dir+'tfr_odd_NE'+st+seed_ch+'-tfr.h5',overwrite =True)\n",
    "                \n",
    "                    tfr_typ_NE = mne.time_frequency.AverageTFR(epochs_aff_typ_NE.info, con_typ_NE.get_data(), times, freqs, len(epochs_aff_typ_NE))\n",
    "                    tfr_typ_NE.save(data_dir+'tfr_typ_NE'+st+seed_ch+'-tfr.h5',overwrite =True)\n",
    "                    \n",
    "                    \n",
    "                    # TFR differences in freq bands and time period 0 to 1.5s\n",
    "                \n",
    "                    tfr_E = tfr_odd_E- tfr_typ_E\n",
    "                    tfr_NE = tfr_odd_NE- tfr_typ_NE\n",
    "                \n",
    "                    freq_band = ['Theta', 'Alpha', 'Low beta', 'High beta']\n",
    "                        \n",
    "                    n_channels = len(tfr_E.copy().pick('eeg').ch_names)\n",
    "                    X1 = []\n",
    "                    X2 = []\n",
    "                    for n, band in enumerate(freq_band):\n",
    "                        tfr_E_ch = []\n",
    "                        tfr_NE_ch = []\n",
    "                        for ch in range(n_channels):\n",
    "                            tfr_E_ch.append((tfr_E.data[:,:,:].mean(axis=2)[ch,n]))\n",
    "                            tfr_NE_ch.append((tfr_NE.data[:,:,:].mean(axis=2)[ch,n]))\n",
    "            \n",
    "                        tfr_E_ch = np.array(tfr_E_ch).reshape(n_channels,1)   \n",
    "                        tfr_NE_ch = np.array(tfr_NE_ch).reshape(n_channels,1)   \n",
    "            \n",
    "                        X1.append(tfr_E_ch)\n",
    "                        X2.append(tfr_NE_ch)\n",
    "                \n",
    "                    coh_E_diff.append(X1)\n",
    "                    coh_NE_diff.append(X2)\n",
    "                coh_diff_E_permuted.append(coh_E_diff)\n",
    "                coh_diff_NE_permuted.append(coh_NE_diff)\n",
    "                \n",
    "            coh_diff_E_permuted1 = np.array(coh_diff_E_permuted)\n",
    "            coh_diff_NE_permuted1 = np.array(coh_diff_NE_permuted)\n",
    "    \n",
    "            file = f\"{result_dir}coh_diff_E_permuted_{n_perms}_{sub}_{st}_{tmin_coh}_{tmax_coh}_center\"\n",
    "    \n",
    "            np.save(file, coh_diff_E_permuted1)\n",
    "            \n",
    "            file = f\"{result_dir}coh_diff_NE_permuted_{n_perms}_{sub}_{st}_{tmin_coh}_{tmax_coh}_center\"\n",
    "    \n",
    "            np.save(file, coh_diff_NE_permuted1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2d4986-8eee-4363-b5d8-3a61f338fbba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
